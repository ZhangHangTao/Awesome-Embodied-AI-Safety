# Awesome-Embodied-AI-Safety [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of publications on safety in Embodied AI, including topics like adversarial attacks, alignment, backdoor, jailbreak, prompt injection, surveys, and safety frameworks.

<strong>Last Update: Feb. 1st, 2025</strong>.

This repository is supported by the Trustworthy Artificial Intelligence ([T-AI](http://trustai.cse.hust.edu.cn/)) Lab at Huazhong University of Science and Technology (HUST). We will try our best to continuously maintain this Github Repository in a weekly manner. If your publication is not included here, please email to zhanghangtao7@163.com


## Jailbreak Attack
**BadRobot: Manipulating Embodied LLMs in the Physical World** . ICLR 2025 `Jailbreak attack on embodied AI robots`  [[pdf](https://arxiv.org/abs/2407.20242)] [[code](https://github.com/gyNancy/phash_public)] Citation: 9


## Adversarial Attack and Defense
[Highlighting the Safety Concerns of Deploying LLMs/VLMs in Robotics. ArXiv 2024](https://arxiv.org/abs/2402.10340) Citation: 20

[Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics. ArXiv 2024](https://arxiv.org/abs/2411.13587) Citation: 0

[Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers. ArXiv 2024](https://arxiv.org/abs/2405.12424) Citation: 7

[Exploring the Robustness of Decision-Level Through Adversarial Attacks on LLM-Based Embodied Models. ACM MM 2024](https://dl.acm.org/doi/abs/10.1145/3664647.3680616) Citation: 4

[Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems. IROS 2024](https://ieeexplore.ieee.org/abstract/document/10802618) Citation: 3


## Backdoor Attack and Defense

[**TrojanRobot: Backdoor Attacks Against LLM-based Embodied Robots in the Physical World**. Arxiv 2024](https://arxiv.org/abs/2411.11683) Citation: 2

[Compromising Embodied Agents with Contextual Backdoor Attacks. Arxiv 2024](https://arxiv.org/abs/2408.02882) Citation: 5

[Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems. Arxiv 2024](https://arxiv.org/abs/2405.20774) Citation: 7



## Alignment
[Robots Enact Malignant Stereotypes. FAccT 2022](https://dl.acm.org/doi/abs/10.1145/3531146.3533138) Citation: 60

[LLM-Driven Robots Risk Enacting Discrimination, Violence, and Unlawful Actions. ArXiv 2024](https://arxiv.org/abs/2406.08824) Citation: 5

[EAIRiskBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents. ArXiv 2024](https://arxiv.org/abs/2408.04449) Citation: 0


## Prompt Injection Attack 
[A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems. ISSRE Wksp 2024](https://ieeexplore.ieee.org/abstract/document/10771340/) Citation: 0


## Safety Frameworks 
[Donâ€™t Let Your Robot be Harmful: Responsible Robotic Manipulation. ArXiv 2024](https://arxiv.org/abs/2411.18289) Citation: 0

[Safeembodai: a safety framework for mobile robots in embodied ai systems. ArXiv 2024](https://arxiv.org/abs/2409.01630) Citation: 2
