# Awesome-Embodied-AI-Safety [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of publications on safety in Embodied AI, including topics like adversarial attacks, alignment, backdoor, jailbreak, prompt injection, surveys, and safety frameworks.

<strong>Last Update: Feb. 1st, 2025</strong>.

This repository is supported by the Trustworthy Artificial Intelligence ([T-AI](http://trustai.cse.hust.edu.cn/)) Lab at Huazhong University of Science and Technology (HUST). We will try our best to continuously maintain this Github Repository in a weekly manner. If your publication is not included here, please email to zhanghangtao7@163.com


## Jailbreak Attack
**ðŸ˜ˆBadRobot: Manipulating Embodied LLMs in the Physical World** . ICLR 2025. `Three jailbreak attacks in the black-box setting`  [[pdf](https://arxiv.org/abs/2407.20242)] [[code](https://github.com/gyNancy/phash_public)] Citation: 9

<!--**Jailbreaking LLM-Controlled Robots**. Arxiv 2024. 'Jailbreak attacks in the white-box, gray-box, and black-box settings' [[pdf](https://arxiv.org/abs/2410.13691)] Citation: 7

**POEX: Policy Executable Embodied AI Jailbreak Attacks**. Arxiv 2024. [[pdf](https://arxiv.org/abs/2412.16633)] Citation: 0 -->


## Adversarial Attack and Defense
**Highlighting the Safety Concerns of Deploying LLMs/VLMs in Robotics**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2402.10340)] Citation: 20

**Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2411.13587)] Citation: 0

**Rethinking Robustness Assessment: Adversarial Attacks on Learning-based Quadrupedal Locomotion Controllers**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2405.12424)] Citation: 7

**Exploring the Robustness of Decision-Level Through Adversarial Attacks on LLM-Based Embodied Models**. ACM MM 2024. [[pdf](https://dl.acm.org/doi/abs/10.1145/3664647.3680616)] Citation: 4

**Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems**. IROS 2024. [[pdf](https://ieeexplore.ieee.org/abstract/document/10802618)] Citation: 3


## Backdoor Attack and Defense
**TrojanRobot: Backdoor Attacks Against LLM-based Embodied Robots in the Physical World**. Arxiv 2024. [[pdf](https://arxiv.org/abs/2411.11683)] Citation: 2

**Compromising Embodied Agents with Contextual Backdoor Attacks**. Arxiv 2024. [[pdf](https://arxiv.org/abs/2408.02882)] Citation: 5

**Can We Trust Embodied Agents? Exploring Backdoor Attacks against Embodied LLM-Based Decision-Making Systems**. Arxiv 2024. [[pdf](https://arxiv.org/abs/2405.20774)] Citation: 7


## Alignment
**Robots Enact Malignant Stereotypes**. FAccT 2022. [[pdf](https://dl.acm.org/doi/abs/10.1145/3531146.3533138)] Citation: 60

**LLM-Driven Robots Risk Enacting Discrimination, Violence, and Unlawful Actions**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2406.08824)] Citation: 5

**EAIRiskBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2408.04449)] Citation: 0


## Prompt Injection Attack 
**A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems**. ISSRE Wksp 2024. [[pdf](https://ieeexplore.ieee.org/abstract/document/10771340/)] Citation: 0


## Safety Frameworks 
**Donâ€™t Let Your Robot be Harmful: Responsible Robotic Manipulation**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2411.18289)] Citation: 0

**Safeembodai: A Safety Framework for Mobile Robots in Embodied AI Systems**. ArXiv 2024. [[pdf](https://arxiv.org/abs/2409.01630)] Citation: 2
